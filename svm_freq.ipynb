{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data = np.loadtxt('data/rt-polaritydata/rt-polarity.pos', dtype=str, delimiter='\\n')\n",
    "neg_data = np.loadtxt('data/rt-polaritydata/rt-polarity.neg', dtype=str, delimiter='\\n')\n",
    "pos_label = np.array([0]*len(pos_data))\n",
    "neg_label = np.array([1]*len(neg_data))\n",
    "data = np.concatenate([pos_data, neg_data])\n",
    "label = np.concatenate([pos_label, neg_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(input='content', decode_error='ignore', strip_accents='unicode', max_df=0.7, min_df=6)\n",
    "vectorizer = CountVectorizer(input='content', decode_error='ignore')\n",
    "vectors = vectorizer.fit_transform(data).toarray()\n",
    "vectors_and_labels = np.array([np.array([vectors[i],label[i]]) for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([0, 0, 0, ..., 0, 0, 0], dtype=int64) 0]\n",
      " [array([0, 0, 0, ..., 0, 0, 0], dtype=int64) 1]\n",
      " [array([0, 0, 0, ..., 0, 0, 0], dtype=int64) 0]\n",
      " ...\n",
      " [array([0, 0, 0, ..., 0, 0, 0], dtype=int64) 0]\n",
      " [array([0, 0, 0, ..., 0, 0, 0], dtype=int64) 1]\n",
      " [array([0, 0, 0, ..., 0, 0, 0], dtype=int64) 0]]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(vectors_and_labels)\n",
    "print(vectors_and_labels)\n",
    "\n",
    "test_data, train_data = vectors_and_labels[:500], vectors_and_labels[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, PredefinedSplit, GridSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.svm import LinearSVC, SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2500 out of 2500 | elapsed: 110.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Linear SVM\n",
      "{'C': 0.03562303127855104, 'dual': False, 'tol': 0.5782808676307457}\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(max_iter=20000)\n",
    "svm_params = {\n",
    "    \"tol\": uniform(0,1),\n",
    "    \"C\": uniform(0,10),\n",
    "    \"dual\": (True, False),\n",
    "#     \"random_state\": randint(0,64)\n",
    "}\n",
    "\n",
    "svm = RandomizedSearchCV(svm, svm_params, n_iter=500, scoring=\"accuracy\", cv=5, verbose=1)\n",
    "\n",
    "svm.fit(train_data[:,0].tolist(), train_data[:,1].tolist())\n",
    "print(\"Best params for Linear SVM\")\n",
    "print(svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy\n",
      "0.9235386734894706\n",
      "Test Accuracy\n",
      "0.768\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy\")\n",
    "print(svm.score(train_data[:,0].tolist(), train_data[:,1].tolist()))\n",
    "print(\"Test Accuracy\")\n",
    "print(svm.score(test_data[:,0].tolist(), test_data[:,1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2500 out of 2500 | elapsed: 340.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for NB\n",
      "{'var_smoothing': 0.002736118051540739}\n",
      "Train Accuracy\n",
      "0.8980515646526275\n",
      "Test Accuracy\n",
      "0.772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_Classifier_freq = GaussianNB()\n",
    "params = {'var_smoothing': uniform(0,1e-2)}\n",
    "NB_freq = RandomizedSearchCV(NB_Classifier_freq, params, n_iter=500, scoring=\"accuracy\", cv=5, verbose=1)\n",
    "\n",
    "NB_freq.fit(train_data[:,0].tolist(), train_data[:,1].tolist())\n",
    "\n",
    "print(\"Best params for NB\")\n",
    "print(NB_freq.best_params_)\n",
    "print(\"Train Accuracy\")\n",
    "print(NB_freq.score(train_data[:,0].tolist(), train_data[:,1].tolist()))\n",
    "print(\"Test Accuracy\")\n",
    "print(NB_freq.score(test_data[:,0].tolist(), test_data[:,1].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2500 out of 2500 | elapsed: 247.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for dt\n",
      "{'criterion': 'entropy', 'max_depth': 1662, 'min_samples_leaf': 28, 'splitter': 'random'}\n",
      "Train Accuracy\n",
      "0.6658138161779177\n",
      "Test Accuracy\n",
      "0.646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Tree_Classifier = DecisionTreeClassifier()\n",
    "dt_params = {\n",
    "    \"criterion\": (\"gini\", \"entropy\"),\n",
    "    \"splitter\": (\"best\", \"random\"),\n",
    "    \"max_depth\": randint(1, 2000),\n",
    "    \"min_samples_leaf\": randint(1, 2000)\n",
    "}\n",
    "\n",
    "dt = RandomizedSearchCV(Tree_Classifier, dt_params, n_iter=500, scoring=\"f1_micro\", cv=5, verbose=1)\n",
    "\n",
    "dt.fit(train_data[:,0].tolist(), train_data[:,1].tolist())\n",
    "\n",
    "print(\"Best params for dt\")\n",
    "print(dt.best_params_)\n",
    "print(\"Train Accuracy\")\n",
    "print(dt.score(train_data[:,0].tolist(), train_data[:,1].tolist()))\n",
    "print(\"Test Accuracy\")\n",
    "print(dt.score(test_data[:,0].tolist(), test_data[:,1].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier(algorithm='kd_tree')\n",
    "\n",
    "# k = [i for i in range(200)]\n",
    "\n",
    "# params = {'n_neighbors': k}\n",
    "\n",
    "# k_nn = GridSearchCV(knn, params, scoring=\"accuracy\", cv=5, verbose=10)\n",
    "\n",
    "# k_nn.fit(train_data[:,0].tolist(), train_data[:,1].tolist())\n",
    "\n",
    "# print(\"Best params for NB\")\n",
    "# print(k_nn.best_params_)\n",
    "# print(k_nn.best_score_)\n",
    "\n",
    "# print(\"Train Accuracy\")\n",
    "# print(k_nn.score(train_data[:,0].tolist(), train_data[:,1].tolist()))\n",
    "# print(\"Test Accuracy\")\n",
    "# print(k_nn.score(test_data[:,0].tolist(), test_data[:,1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_Classifier = RandomForestClassifier()\n",
    "dt_params = {\n",
    "    \"n_estimators\": randint(100,400),\n",
    "    \"min_samples_leaf\": randint(3, 20)\n",
    "}\n",
    "dt = RandomizedSearchCV(RF_Classifier, dt_params, n_iter=20, scoring=\"accuracy\", cv=5, verbose=1)\n",
    "\n",
    "dt.fit(train_data[:,0].tolist(), train_data[:,1].tolist())\n",
    "\n",
    "print(\"Best params for dt\")\n",
    "print(dt.best_params_)\n",
    "print(\"Train Accuracy\")\n",
    "print(dt.score(train_data[:,0].tolist(), train_data[:,1].tolist()))\n",
    "print(\"Test Accuracy\")\n",
    "print(dt.score(test_data[:,0].tolist(), test_data[:,1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
